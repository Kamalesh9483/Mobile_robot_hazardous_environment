{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from pathlib import Path\n",
    "# import os.path\n",
    "# import matplotlib.pyplot as plt\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # # Create a list with the filepaths for training and testing\n",
    "# train_dir = Path('C:/Projects/Mobile robot in hazardous environment/Agricultural Robot/Tomato/Tomato_Images/Train')\n",
    "# # train_filepaths = list(train_dir.glob(r'**/*.jpg'))\n",
    "\n",
    "# test_dir = Path('C:/Projects/Mobile robot in hazardous environment/Agricultural Robot/Tomato/Tomato_Images/Test')\n",
    "# # test_filepaths = list(test_dir.glob(r'**/*.jpg'))\n",
    "\n",
    "# val_dir = Path('C:/Projects/Mobile robot in hazardous environment/Agricultural Robot/Tomato/Tomato_Images/Validation')\n",
    "# # val_filepaths = list(test_dir.glob(r'**/*.jpg'))\n",
    "\n",
    "# # def proc_img(filepath):\n",
    "\n",
    "# #     labels = [str(filepath[i]).split(\"/\")[-1] \\\n",
    "# #               for i in range(len(filepath))]\n",
    "\n",
    "# #     filepath = pd.Series(filepath, name='Filepath').astype(str)\n",
    "# #     labels = pd.Series(labels, name='Label')\n",
    "    \n",
    "# #     labels = pd.Series(labels, name='Label')\n",
    "# #     # Concatenate filepaths and labels\n",
    "# #     df = pd.concat([filepath, labels], axis=1)\n",
    "\n",
    "# #     # Shuffle the DataFrame and reset index\n",
    "# #     df = df.sample(frac=1).reset_index(drop = True)\n",
    "    \n",
    "# #     return df\n",
    "\n",
    "# # train_df = os.listdir(train_filepaths)\n",
    "# # test_df = proc_img(test_filepaths)\n",
    "# # val_df = proc_img(val_filepaths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 118 files [00:00, 174.04 files/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import splitfolders\n",
    "splitfolders.ratio('./Tomato_Images', output=\"output\", seed=1337, ratio=(.8, 0.1,0.1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Training set --\n",
      "\n",
      "Number of pictures: 90\n",
      "\n",
      "Number of different labels: 90\n",
      "\n",
      "Labels: ['C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_70.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_88.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_38.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_90.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_99.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_82.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_72.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_87.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_91.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_49.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_56.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_76.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_50.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_45.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_14.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_34.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_57.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_21.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_69.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_61.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_52.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_60.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_26.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_95.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_8.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_100.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_81.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_24.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_6.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_23.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_86.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_54.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_41.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_96.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_36.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_20.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_22.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_74.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_79.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_98.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_29.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_11.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_77.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_59.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_15.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_51.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_89.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_66.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_37.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_67.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_78.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_97.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_9.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_5.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_84.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_10.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_2.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_4.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_43.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_32.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_16.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_71.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_28.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_58.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_73.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_55.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_40.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_47.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_7.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_63.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_17.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_68.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_13.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_18.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_64.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_27.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_1.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_65.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_12.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_33.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_30.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_19.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_85.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_39.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_53.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_83.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_25.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_93.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_3.jpg'\n",
      " 'C:\\\\Projects\\\\Mobile robot in hazardous environment\\\\Agricultural Robot\\\\Tomato\\\\Tomato_Images\\\\Train\\\\Image_44.jpg']\n"
     ]
    }
   ],
   "source": [
    "print('-- Training set --\\n')\n",
    "print(f'Number of pictures: {train_df.shape[0]}\\n')\n",
    "print(f'Number of different labels: {len(train_df.Label.unique())}\\n')\n",
    "print(f'Labels: {train_df.Label.unique()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>C:\\Projects\\Mobile robot in hazardous environm...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>C:\\Projects\\Mobile robot in hazardous environm...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>C:\\Projects\\Mobile robot in hazardous environm...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>C:\\Projects\\Mobile robot in hazardous environm...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>C:\\Projects\\Mobile robot in hazardous environm...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Filepath Label\n",
       "85  C:\\Projects\\Mobile robot in hazardous environm...   NaN\n",
       "86  C:\\Projects\\Mobile robot in hazardous environm...   NaN\n",
       "87  C:\\Projects\\Mobile robot in hazardous environm...   NaN\n",
       "88  C:\\Projects\\Mobile robot in hazardous environm...   NaN\n",
       "89  C:\\Projects\\Mobile robot in hazardous environm...   NaN"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a DataFrame with one Label of each category\n",
    "# df_unique = train_df.copy().drop_duplicates(subset=[\"Label\"]).reset_index()\n",
    "\n",
    "# # Display some pictures of the dataset\n",
    "# fig, axes = plt.subplots(nrows=6, ncols=6, figsize=(8, 7),\n",
    "#                         subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "# for i, ax in enumerate(axes.flat):\n",
    "#     ax.imshow(plt.imread(df_unique.Filepath[i]))\n",
    "#     ax.set_title(df_unique.Label[i], fontsize = 12)\n",
    "# plt.tight_layout(pad=0.5)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 90 validated image filenames belonging to 90 classes.\n",
      "Found 10 validated image filenames belonging to 10 classes.\n",
      "Found 10 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",
    ")\n",
    "\n",
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",
    ")\n",
    "\n",
    "train_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=0,\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "val_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=0,\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 26s 3us/step\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    pooling='avg'\n",
    ")\n",
    "pretrained_model.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3/3 [==============================] - ETA: 0s - loss: 4.6372 - accuracy: 0.0111   "
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " logits and labels must be broadcastable: logits_size=[10,90] labels_size=[10,10]\n\t [[node categorical_crossentropy/softmax_cross_entropy_with_logits (defined at \\Temp\\ipykernel_14064\\1199187726.py:16) ]] [Op:__inference_test_function_31961]\n\nFunction call stack:\ntest_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14064\\1199187726.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m history = model.fit(\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mtrain_images\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_images\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1212\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1213\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1214\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1215\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1487\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1488\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1489\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1490\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1491\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    954\u001b[0m               *args, **kwds)\n\u001b[0;32m    955\u001b[0m       \u001b[1;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 956\u001b[1;33m       return self._concrete_stateful_fn._call_flat(\n\u001b[0m\u001b[0;32m    957\u001b[0m           filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m    958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  logits and labels must be broadcastable: logits_size=[10,90] labels_size=[10,10]\n\t [[node categorical_crossentropy/softmax_cross_entropy_with_logits (defined at \\Temp\\ipykernel_14064\\1199187726.py:16) ]] [Op:__inference_test_function_31961]\n\nFunction call stack:\ntest_function\n"
     ]
    }
   ],
   "source": [
    "inputs = pretrained_model.input\n",
    "\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(90, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    validation_data=val_images,\n",
    "    batch_size = 10,\n",
    "    epochs=5,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=2,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2cd89a3ea580c4b0ae5d42897241e27273cc7a73769436bcc6886b4e06d16402"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
